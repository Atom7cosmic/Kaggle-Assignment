{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02d24f1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-13T17:45:57.686833Z",
     "iopub.status.busy": "2025-06-13T17:45:57.686506Z",
     "iopub.status.idle": "2025-06-13T17:46:01.820995Z",
     "shell.execute_reply": "2025-06-13T17:46:01.819790Z"
    },
    "papermill": {
     "duration": 4.140243,
     "end_time": "2025-06-13T17:46:01.822783",
     "exception": false,
     "start_time": "2025-06-13T17:45:57.682540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7714074d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:46:01.828900Z",
     "iopub.status.busy": "2025-06-13T17:46:01.828384Z",
     "iopub.status.idle": "2025-06-13T17:46:01.941253Z",
     "shell.execute_reply": "2025-06-13T17:46:01.940108Z"
    },
    "papermill": {
     "duration": 0.117682,
     "end_time": "2025-06-13T17:46:01.943013",
     "exception": false,
     "start_time": "2025-06-13T17:46:01.825331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv(\"/kaggle/input/hackathon/hacktrain.csv\")\n",
    "    test_df = pd.read_csv(\"/kaggle/input/hackathon/hacktest.csv\")\n",
    "    test_ids = test_df['ID']\n",
    "except FileNotFoundError:\n",
    "    print(\"Ensure 'hacktrain.csv' and 'hacktest.csv' are in the same directory.\")\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    test_ids = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b484c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:46:01.948537Z",
     "iopub.status.busy": "2025-06-13T17:46:01.948086Z",
     "iopub.status.idle": "2025-06-13T17:46:01.956381Z",
     "shell.execute_reply": "2025-06-13T17:46:01.955314Z"
    },
    "papermill": {
     "duration": 0.013464,
     "end_time": "2025-06-13T17:46:01.958616",
     "exception": false,
     "start_time": "2025-06-13T17:46:01.945152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    " ndvi_cols = [col for col in df.columns if '_N' in col]\n",
    " ndvi_cols.sort()\n",
    " df[ndvi_cols] = df[ndvi_cols].ffill(axis=1).bfill(axis=1)\n",
    " time_indices = np.arange(len(ndvi_cols))\n",
    " df['ndvi_mean'] = df[ndvi_cols].mean(axis=1)\n",
    " df['ndvi_std'] = df[ndvi_cols].std(axis=1)\n",
    " df['ndvi_max'] = df[ndvi_cols].max(axis=1)\n",
    " df['ndvi_min'] = df[ndvi_cols].min(axis=1)\n",
    " df['ndvi_range'] = df['ndvi_max'] - df['ndvi_min']\n",
    " df['ndvi_median'] = df[ndvi_cols].median(axis=1)\n",
    " df['ndvi_q25'] = df[ndvi_cols].quantile(0.25, axis=1)\n",
    " df['ndvi_q75'] = df[ndvi_cols].quantile(0.75, axis=1)\n",
    " df['ndvi_slope'] = df[ndvi_cols].apply(\n",
    "        lambda row: np.polyfit(time_indices, row.values, 1)[0], axis=1\n",
    "    )\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f914e584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:46:01.964748Z",
     "iopub.status.busy": "2025-06-13T17:46:01.964416Z",
     "iopub.status.idle": "2025-06-13T17:46:02.997917Z",
     "shell.execute_reply": "2025-06-13T17:46:02.996621Z"
    },
    "papermill": {
     "duration": 1.038912,
     "end_time": "2025-06-13T17:46:03.000205",
     "exception": false,
     "start_time": "2025-06-13T17:46:01.961293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not train_df.empty and not test_df.empty:\n",
    "    train_df_featured = create_features(train_df)\n",
    "    test_df_featured = create_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2e3752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:46:03.006230Z",
     "iopub.status.busy": "2025-06-13T17:46:03.005906Z",
     "iopub.status.idle": "2025-06-13T17:46:04.375630Z",
     "shell.execute_reply": "2025-06-13T17:46:04.374808Z"
    },
    "papermill": {
     "duration": 1.376143,
     "end_time": "2025-06-13T17:46:04.378787",
     "exception": false,
     "start_time": "2025-06-13T17:46:03.002644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Validation Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        farm       0.87      0.79      0.83       168\n",
      "      forest       1.00      0.97      0.98      1232\n",
      "       grass       0.60      0.82      0.70        39\n",
      "  impervious       0.89      0.89      0.89       134\n",
      "     orchard       0.12      0.50      0.19         6\n",
      "       water       0.49      0.90      0.63        21\n",
      "\n",
      "    accuracy                           0.94      1600\n",
      "   macro avg       0.66      0.81      0.70      1600\n",
      "weighted avg       0.96      0.94      0.94      1600\n",
      "\n",
      "\n",
      "--- Generating Submission File ---\n",
      "\n",
      "'submission.csv' created successfully!\n",
      "Final class distribution in submission file:\n",
      "class\n",
      "forest    2084\n",
      "water      761\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "if 'class' in train_df_featured.columns:\n",
    "        train_df_featured['class'] = label_encoder.fit_transform(train_df_featured['class'])\n",
    "\n",
    "        X = train_df_featured.drop(columns=['class', 'ID'])\n",
    "        y = train_df_featured['class']\n",
    "\n",
    "        X_final_test = test_df_featured[X.columns]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_final_test_scaled = scaler.transform(X_final_test)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        class_weights = dict(zip(\n",
    "            np.unique(y_train),\n",
    "            compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        ))\n",
    "\n",
    "        model = LogisticRegression(\n",
    "            multi_class='multinomial',\n",
    "            solver='lbfgs',\n",
    "            max_iter=2000,\n",
    "            class_weight=class_weights,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print(\"--- Model Validation Report ---\")\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        print(classification_report(\n",
    "            y_val, y_val_pred,\n",
    "            target_names=label_encoder.classes_\n",
    "        ))\n",
    "\n",
    "        print(\"\\n--- Generating Submission File ---\")\n",
    "        final_predictions_encoded = model.predict(X_final_test_scaled)\n",
    "        final_predictions_decoded = label_encoder.inverse_transform(final_predictions_encoded)\n",
    "\n",
    "        submission_df = pd.DataFrame({'ID': test_ids, 'class': final_predictions_decoded})\n",
    "        submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "        print(\"\\n'submission.csv' created successfully!\")\n",
    "        print(\"Final class distribution in submission file:\")\n",
    "        print(submission_df['class'].value_counts())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12585144,
     "sourceId": 104491,
     "sourceType": "competition"
    },
    {
     "datasetId": 7640796,
     "sourceId": 12133193,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7641621,
     "sourceId": 12134353,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.794735,
   "end_time": "2025-06-13T17:46:05.107239",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-13T17:45:52.312504",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
